{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First lets improve libraries that we are going to be used in this lab session\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from collections import Counter\n",
    "import pickle as pkl\n",
    "import random\n",
    "import pdb\n",
    "random.seed(134)\n",
    "import pandas as pd\n",
    "\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "BATCH_SIZE = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# max_vocab_size = 25000\n",
    "PAD_IDX = 0\n",
    "UNK_IDX = 1\n",
    "\n",
    "def build_vocab(all_tokens):\n",
    "    token_counter = Counter(all_tokens)\n",
    "#     print(token_counter)\n",
    "    vocab = token_counter.keys()\n",
    "    id2token = list(vocab)\n",
    "    token2id = dict(zip(vocab, range(2,2+len(vocab)))) \n",
    "    id2token = ['<pad>', '<unk>'] + id2token\n",
    "    token2id['<pad>'] = PAD_IDX \n",
    "    token2id['<unk>'] = UNK_IDX\n",
    "    return token2id, id2token\n",
    "\n",
    "def read_data(fine_name):\n",
    "    df = pd.read_csv(fine_name,sep='\\t')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"mnli_val.tsv\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>'Not entirely , ' I snapped , harsher than int...</td>\n",
       "      <td>I spoke more harshly than I wanted to .</td>\n",
       "      <td>entailment</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cook and then the next time it would be my tur...</td>\n",
       "      <td>I would cook and then the next turn would be h...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The disorder hardly seemed to exist before the...</td>\n",
       "      <td>The disorder did n't seem to be as common when...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>slate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Report and Order , in large part , adopts ...</td>\n",
       "      <td>The Report and Order ignores recommendations f...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IDPA 's OIG 's mission is to prevent , detect ...</td>\n",
       "      <td>IDPA 's OIG 's mission is clear and cares abou...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  'Not entirely , ' I snapped , harsher than int...   \n",
       "1  cook and then the next time it would be my tur...   \n",
       "2  The disorder hardly seemed to exist before the...   \n",
       "3  The Report and Order , in large part , adopts ...   \n",
       "4  IDPA 's OIG 's mission is to prevent , detect ...   \n",
       "\n",
       "                                           sentence2          label  \\\n",
       "0            I spoke more harshly than I wanted to .     entailment   \n",
       "1  I would cook and then the next turn would be h...  contradiction   \n",
       "2  The disorder did n't seem to be as common when...     entailment   \n",
       "3  The Report and Order ignores recommendations f...  contradiction   \n",
       "4  IDPA 's OIG 's mission is clear and cares abou...     entailment   \n",
       "\n",
       "        genre  \n",
       "0     fiction  \n",
       "1   telephone  \n",
       "2       slate  \n",
       "3  government  \n",
       "4  government  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count           5000\n",
       "unique             5\n",
       "top       government\n",
       "freq            1016\n",
       "Name: genre, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['genre'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(df):\n",
    "    df['sentence1'] = df['sentence1'].apply(lambda x: [a.lower() for a in x.split(' ')])\n",
    "    df['sentence2'] = df['sentence2'].apply(lambda x : [a.lower() for a in x.split(' ')])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = tokenize(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['not, entirely, ,, ', i, snapped, ,, harsher,...</td>\n",
       "      <td>[i, spoke, more, harshly, than, i, wanted, to, .]</td>\n",
       "      <td>entailment</td>\n",
       "      <td>fiction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cook, and, then, the, next, time, it, would, ...</td>\n",
       "      <td>[i, would, cook, and, then, the, next, turn, w...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>telephone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[the, disorder, hardly, seemed, to, exist, bef...</td>\n",
       "      <td>[the, disorder, did, n't, seem, to, be, as, co...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>slate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[the, report, and, order, ,, in, large, part, ...</td>\n",
       "      <td>[the, report, and, order, ignores, recommendat...</td>\n",
       "      <td>contradiction</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[idpa, 's, oig, 's, mission, is, to, prevent, ...</td>\n",
       "      <td>[idpa, 's, oig, 's, mission, is, clear, and, c...</td>\n",
       "      <td>entailment</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  ['not, entirely, ,, ', i, snapped, ,, harsher,...   \n",
       "1  [cook, and, then, the, next, time, it, would, ...   \n",
       "2  [the, disorder, hardly, seemed, to, exist, bef...   \n",
       "3  [the, report, and, order, ,, in, large, part, ...   \n",
       "4  [idpa, 's, oig, 's, mission, is, to, prevent, ...   \n",
       "\n",
       "                                           sentence2          label  \\\n",
       "0  [i, spoke, more, harshly, than, i, wanted, to, .]     entailment   \n",
       "1  [i, would, cook, and, then, the, next, turn, w...  contradiction   \n",
       "2  [the, disorder, did, n't, seem, to, be, as, co...     entailment   \n",
       "3  [the, report, and, order, ignores, recommendat...  contradiction   \n",
       "4  [idpa, 's, oig, 's, mission, is, clear, and, c...     entailment   \n",
       "\n",
       "        genre  \n",
       "0     fiction  \n",
       "1   telephone  \n",
       "2       slate  \n",
       "3  government  \n",
       "4  government  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_load = 100000\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "with open('wiki-news-300d-1M.vec') as f:\n",
    "    loaded_embeddings = np.zeros((words_to_load+2, 300))\n",
    "    words = {}\n",
    "    idx2words = {}\n",
    "    ordered_words = ['<pad>','<unk>']\n",
    "    i = 2\n",
    "    for line in f:\n",
    "        if i-2 >= words_to_load: \n",
    "            break\n",
    "        s = line.split()\n",
    "        loaded_embeddings[i, :] = np.asarray(s[1:])\n",
    "        words[s[0]] = i\n",
    "        idx2words[i] = s[0]\n",
    "        ordered_words.append(s[0])\n",
    "        i = i+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "words['<pad>'] = 0\n",
    "words['<unk>'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2words[0] = \"<pad>\"\n",
    "idx2words[1] = \"<unk>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# words\n",
    "def apply_idz(x):\n",
    "    temp = []\n",
    "    for a in x:\n",
    "        if a in ordered_words:\n",
    "            temp.append(words[a])\n",
    "        else:\n",
    "            temp.append(1)\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def idize(df):\n",
    "    df['sentence1_idz'] = df[\"sentence1\"].apply(apply_idz)\n",
    "    df['sentence2_idz'] = df[\"sentence2\"].apply(apply_idz)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = idize(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_vec = np.random.normal(size=300)\n",
    "pad_vec = np.random.normal(size=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_embeddings[0,:] = pad_vec\n",
    "# np.insert(loaded_embeddings,0,pad_vec,axis=0)\n",
    "loaded_embeddings[1,:] = unk_vec\n",
    "# np.insert(loaded_embeddings,1,unk_vec,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_target(train_train):\n",
    "    train_train['label'][train_train['label']=='neutral']=0\n",
    "    train_train['label'][train_train['label']=='entailment']=1\n",
    "    train_train['label'][train_train['label']=='contradiction']=2\n",
    "    return train_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test =encode_target(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "      <th>genre</th>\n",
       "      <th>sentence1_idz</th>\n",
       "      <th>sentence2_idz</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>['not, entirely, ,, ', i, snapped, ,, harsher,...</td>\n",
       "      <td>[i, spoke, more, harshly, than, i, wanted, to, .]</td>\n",
       "      <td>1</td>\n",
       "      <td>fiction</td>\n",
       "      <td>[1, 1862, 3, 26, 673, 13671, 3, 32878, 103, 25...</td>\n",
       "      <td>[673, 3528, 54, 26749, 103, 673, 1198, 8, 5]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[cook, and, then, the, next, time, it, would, ...</td>\n",
       "      <td>[i, would, cook, and, then, the, next, turn, w...</td>\n",
       "      <td>2</td>\n",
       "      <td>telephone</td>\n",
       "      <td>[7496, 6, 90, 4, 425, 66, 22, 84, 41, 96, 954,...</td>\n",
       "      <td>[673, 84, 7496, 6, 90, 4, 425, 954, 84, 41, 45...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[the, disorder, hardly, seemed, to, exist, bef...</td>\n",
       "      <td>[the, disorder, did, n't, seem, to, be, as, co...</td>\n",
       "      <td>1</td>\n",
       "      <td>slate</td>\n",
       "      <td>[4, 4788, 3685, 2567, 8, 1296, 121, 4, 40018, ...</td>\n",
       "      <td>[4, 4788, 155, 1, 1354, 8, 41, 21, 640, 74, 1,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[the, report, and, order, ,, in, large, part, ...</td>\n",
       "      <td>[the, report, and, order, ignores, recommendat...</td>\n",
       "      <td>2</td>\n",
       "      <td>government</td>\n",
       "      <td>[4, 301, 6, 573, 3, 9, 543, 277, 3, 22355, 4, ...</td>\n",
       "      <td>[4, 301, 6, 573, 12354, 2866, 29, 5436, 1969, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[idpa, 's, oig, 's, mission, is, to, prevent, ...</td>\n",
       "      <td>[idpa, 's, oig, 's, mission, is, clear, and, c...</td>\n",
       "      <td>1</td>\n",
       "      <td>government</td>\n",
       "      <td>[1, 27, 1, 27, 1301, 16, 8, 1794, 3, 7763, 3, ...</td>\n",
       "      <td>[1, 27, 1, 27, 1301, 16, 478, 6, 11894, 49, 27...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  ['not, entirely, ,, ', i, snapped, ,, harsher,...   \n",
       "1  [cook, and, then, the, next, time, it, would, ...   \n",
       "2  [the, disorder, hardly, seemed, to, exist, bef...   \n",
       "3  [the, report, and, order, ,, in, large, part, ...   \n",
       "4  [idpa, 's, oig, 's, mission, is, to, prevent, ...   \n",
       "\n",
       "                                           sentence2 label       genre  \\\n",
       "0  [i, spoke, more, harshly, than, i, wanted, to, .]     1     fiction   \n",
       "1  [i, would, cook, and, then, the, next, turn, w...     2   telephone   \n",
       "2  [the, disorder, did, n't, seem, to, be, as, co...     1       slate   \n",
       "3  [the, report, and, order, ignores, recommendat...     2  government   \n",
       "4  [idpa, 's, oig, 's, mission, is, clear, and, c...     1  government   \n",
       "\n",
       "                                       sentence1_idz  \\\n",
       "0  [1, 1862, 3, 26, 673, 13671, 3, 32878, 103, 25...   \n",
       "1  [7496, 6, 90, 4, 425, 66, 22, 84, 41, 96, 954,...   \n",
       "2  [4, 4788, 3685, 2567, 8, 1296, 121, 4, 40018, ...   \n",
       "3  [4, 301, 6, 573, 3, 9, 543, 277, 3, 22355, 4, ...   \n",
       "4  [1, 27, 1, 27, 1301, 16, 8, 1794, 3, 7763, 3, ...   \n",
       "\n",
       "                                       sentence2_idz  \n",
       "0       [673, 3528, 54, 26749, 103, 673, 1198, 8, 5]  \n",
       "1  [673, 84, 7496, 6, 90, 4, 425, 954, 84, 41, 45...  \n",
       "2  [4, 4788, 155, 1, 1354, 8, 41, 21, 640, 74, 1,...  \n",
       "3  [4, 301, 6, 573, 12354, 2866, 29, 5436, 1969, ...  \n",
       "4  [1, 27, 1, 27, 1301, 16, 478, 6, 11894, 49, 27...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SnliDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        s1_full = self.df.iloc[idx]['sentence1']\n",
    "        s2_full = self.df.iloc[idx]['sentence2']\n",
    "        s1 = self.df.iloc[idx]['sentence1_idz']\n",
    "        s2 = self.df.iloc[idx]['sentence2_idz']\n",
    "        tar = self.df.iloc[idx]['label']\n",
    "        len1 = len(s1)\n",
    "        len2 = len(s2)\n",
    "#         print(idx)\n",
    "        return [s1,len1,s2,len2,tar,idx]\n",
    "#         return [s1,len1,s2,len2,tar,s1_full,s2_full]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LEN = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_collate_func(batch):\n",
    "    data_list_s1 = []\n",
    "    data_list_s2 = []\n",
    "    label_list = []\n",
    "    length_list_s1 = []\n",
    "    length_list_s2 = []\n",
    "    idx = []\n",
    "    s1_full = []\n",
    "    s2_full = []\n",
    "    for datum in batch:\n",
    "        label_list.append(datum[4])\n",
    "        length_list_s1.append(datum[1])\n",
    "        length_list_s2.append(datum[3])\n",
    "        idx.append(datum[5])\n",
    "#         s1_full.append()\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        if datum[1]>MAX_LEN:\n",
    "            padded_vec_s1 = np.array(datum[0])[:MAX_LEN]\n",
    "        else:\n",
    "            padded_vec_s1 = np.pad(np.array(datum[0]),\n",
    "                                pad_width=((0,MAX_LEN - datum[1])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        if datum[3]>MAX_LEN:\n",
    "            padded_vec_s2 = np.array(datum[2])[:MAX_LEN]\n",
    "        else:\n",
    "            padded_vec_s2 = np.pad(np.array(datum[2]),\n",
    "                                pad_width=((0,MAX_LEN - datum[3])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list_s1.append(padded_vec_s1)\n",
    "        data_list_s2.append(padded_vec_s2)\n",
    "        \n",
    "    return [torch.from_numpy(np.array(data_list_s1)), torch.LongTensor(length_list_s1), torch.from_numpy(np.array(data_list_s2)), torch.LongTensor(length_list_s2), torch.LongTensor(label_list),torch.LongTensor(idx)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = SnliDataset(df_test)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                           batch_size=10,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_genre(dataset,model):\n",
    "    train_fiction = SnliDataset(dataset)\n",
    "    train_loader_fiction = torch.utils.data.DataLoader(dataset=train_fiction,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "    total=0\n",
    "    correct=0\n",
    "    for (data1, length1, data2, length2, labels,idx) in train_loader_fiction:\n",
    "#                 data_batch1, length_batch1, data_batch2, len_batch2, label_batch = data1, length1, data2, length2, labels\n",
    "        data_batch1, len_batch1, data_batch2, len_batch2, label_batch,idx_batch = data1.cuda(), length1.cuda(), data2.cuda(), length2.cuda(), labels.cuda(),idx\n",
    "        outputs = model(data_batch1, len_batch1, data_batch2, len_batch2)\n",
    "\n",
    "\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(label_batch.view_as(predicted)).sum().item()\n",
    "\n",
    "    print(100*correct/total)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_wront(dataset,model):\n",
    "    train_fiction = SnliDataset(dataset)\n",
    "    train_loader_fiction = torch.utils.data.DataLoader(dataset=train_fiction,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=True)\n",
    "    total=0\n",
    "    correct=0\n",
    "    \n",
    "    correct_3 = 0\n",
    "    incorrect_3 = 0\n",
    "    for (data1, length1, data2, length2, labels,idx) in train_loader_fiction:\n",
    "#                 data_batch1, length_batch1, data_batch2, len_batch2, label_batch = data1, length1, data2, length2, labels\n",
    "        data_batch1, len_batch1, data_batch2, len_batch2, label_batch,idx_batch = data1.cuda(), length1.cuda(), data2.cuda(), length2.cuda(), labels.cuda(),idx\n",
    "        outputs = model(data_batch1, len_batch1, data_batch2, len_batch2)\n",
    "\n",
    "\n",
    "        outputs = F.softmax(outputs, dim=1)\n",
    "        predicted = outputs.max(1, keepdim=True)[1]\n",
    "        \n",
    "        mask =(predicted.squeeze(1).eq(label_batch)).cpu().data.numpy()==0\n",
    "#         print(idx.numpy()[mask])\n",
    "        fns = idx.numpy()[mask]\n",
    "        tns = idx.numpy()[np.array(mask)==False]\n",
    "        actual_out = labels.data.numpy()[mask]\n",
    "        actual_true_out = labels.data.numpy()[np.array(mask)==False]\n",
    "        pred_false = predicted.cpu().data.numpy()[mask]\n",
    "        pred_true = predicted.cpu().data.numpy()[np.array(mask)==False]\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(label_batch.view_as(predicted)).sum().item()\n",
    "\n",
    "    print(\"total accuracy\",100*correct/total)\n",
    "    return fns,pred_false,tns,pred_true,actual_out,actual_true_out\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN2(nn.Module):\n",
    "    def __init__(self, emb_size, num_classes, vocab_size,n_feat,n_channel,dp):\n",
    "        super(CNN2, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx = PAD_IDX)\n",
    "        self.embedding.from_pretrained(torch.from_numpy(loaded_embeddings), freeze=False)\n",
    "        self.n_channel =n_channel\n",
    "        self.conv1 = nn.Conv2d(1,n_feat,kernel_size=(3,300),stride=(1,1))\n",
    "        self.conv2 = nn.Conv2d(n_feat,self.n_channel,kernel_size=(5,1),stride=(1,1))\n",
    "        \n",
    "        self.max1 = nn.MaxPool2d(kernel_size=(10,1))\n",
    "        self.linear1 = nn.Linear(2*self.n_channel, 500)\n",
    "        self.linear2 = nn.Linear(500,num_classes)\n",
    "        self.dp1 = nn.Dropout(p=dp)\n",
    "\n",
    "    def forward(self, data_s1, length1, data_s2, length2):\n",
    "\n",
    "        embed1 = torch.unsqueeze(self.embedding(data_s1),dim=1)\n",
    "        embed2 = torch.unsqueeze(self.embedding(data_s2),dim=1)\n",
    "        \n",
    "        out1 = F.relu(self.conv1(embed1))\n",
    "        out2 = F.relu(self.conv1(embed2))\n",
    "        \n",
    "        out1 = F.relu(self.conv2(out1))\n",
    "        out2 = F.relu(self.conv2(out2))\n",
    "\n",
    "#         print(\"out\",out1.size())\n",
    "        mout1 = self.max1(out1)\n",
    "        mout2 = self.max1(out2)\n",
    "#         print(\"mout\",mout1.size())\n",
    "        \n",
    "        sum1 = torch.squeeze(torch.sum(mout1,dim=2))\n",
    "        sum2 = torch.squeeze(torch.sum(mout2,dim=2))\n",
    "#         print(\"sum\",sum1.size())\n",
    "#         combined_out = torch.squeeze(torch.cat([mout1, mout2], dim=1))\n",
    "        combined_out = torch.cat([sum1,sum2],dim=1)\n",
    "#         print(\"comb\",combined_out.size())\n",
    "        \n",
    "        logits = F.relu(self.linear1(self.dp1(combined_out)))\n",
    "        res = self.linear2(logits)\n",
    "        \n",
    "        return res\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(\"model_cnn11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fiction\n",
      "43.015075376884425\n",
      "----------\n",
      "telephone\n",
      "41.39303482587065\n",
      "----------\n",
      "slate\n",
      "41.71656686626746\n",
      "----------\n",
      "government\n",
      "40.15748031496063\n",
      "----------\n",
      "travel\n",
      "42.66802443991853\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for gen in ['fiction', 'telephone', 'slate', 'government', 'travel']:\n",
    "    data_d = df_test[df_test['genre']==gen]\n",
    "    print(gen)\n",
    "    test_genre(data_d,model)\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total accuracy 41.78\n"
     ]
    }
   ],
   "source": [
    "fns,pred_false,tns,pred_true,actual_out,actual_true_out = print_wront(df_test,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3983, 1092, 3559, 3023])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4889, 2382, 2992, 3453])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorrect predictions by CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 1\n",
      "Actual 2\n",
      "sentence1:  the rustic bras-david picnic area , for example , is set alongside a burbling stream .\n",
      "sentence2:  the picnic area is not near a stream .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 0\n",
      "Actual 2\n",
      "sentence1:  his grandson akbar chose agra for his capital over delhi .\n",
      "sentence2:  his grandson chose washington dc as the capital , not new york city .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 0\n",
      "sentence1:  the purpose of the diwan-i-khas is hotly disputed ; it is not necessarily the hall of private audience that its name implies .\n",
      "sentence2:  the hall is not know many people .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 0\n",
      "Actual 2\n",
      "sentence1:  for more than 26 centuries it has witnessed countless declines , falls , and rebirths , and today continues to resist the assaults of brutal modernity in its time-locked , color-rich historical center .\n",
      "sentence2:  the historical center is quite new , and rather bland .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fns)):\n",
    "    print(\"predicted\",pred_false[i][0])\n",
    "    print(\"Actual\",actual_out[i])\n",
    "    print(\"sentence1: \",' '.join(df_test.iloc[fns[i]][\"sentence1\"]))    \n",
    "    print(\"sentence2: \",' '.join(df_test.iloc[fns[i]][\"sentence2\"]))\n",
    "    print()\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct Predictions by CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 1\n",
      "Actual 1\n",
      "sentence1 : the office of information and regulatory affairs of omb approved the\n",
      "sentence2 :  something was approved by the office of affairs .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 2\n",
      "Actual 2\n",
      "sentence1 : programs in michigan and the district of columbia received one-year grant terms for 2002 .\n",
      "sentence2 :  programs in michigan receive no grants at all .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 1\n",
      "sentence1 : alternatively , there are sousa and goncalves ( rua do castanheiro , 47 ) and unibasket ( rua do carmo , 42 ; tel . 291/226 925 ) , both in funchal .\n",
      "sentence2 :  there are other places in funchal .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 2\n",
      "Actual 2\n",
      "sentence1 : so you um-hum so you think it comes down to education or or something like that\n",
      "sentence2 :  it has nothing to do with education .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tns)):\n",
    "    print(\"predicted\",pred_true[i][0])\n",
    "    print(\"Actual\",actual_true_out[i])\n",
    "    print(\"sentence1 :\",' '.join(df_test.iloc[tns[i]][\"sentence1\"]))\n",
    "    print(\"sentence2 : \",' '.join(df_test.iloc[tns[i]][\"sentence2\"]))\n",
    "    print()\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, emb_size, hidden_size, num_layers, num_classes, vocab_size):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.num_layers, self.hidden_size = num_layers, hidden_size\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size, padding_idx=PAD_IDX)\n",
    "#         self.embedding.weight.data.copy_(torch.from_numpy(loaded_embeddings))\n",
    "#         self.embedding.weight.requires_grad = False\n",
    "        self.embedding.from_pretrained(torch.from_numpy(loaded_embeddings).cuda(), freeze = True)\n",
    "\n",
    "\n",
    "        \n",
    "        self.rnn = nn.GRU(emb_size, hidden_size, num_layers, batch_first = True)\n",
    "        self.linear1 = nn.Linear(2*hidden_size, 500)\n",
    "        self.linear2 = nn.Linear(500,num_classes)\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        hidden = torch.randn(self.num_layers, batch_size, self.hidden_size)\n",
    "        return hidden.cuda()\n",
    "\n",
    "    def forward(self, data_s1, length1, data_s2, length2):  \n",
    "        batch_size = data_s1.size(0)\n",
    "        self.hidden1 = self.init_hidden(batch_size)\n",
    "        self.hidden2 = self.init_hidden(batch_size)\n",
    "\n",
    "        embed1 = self.embedding(data_s1)\n",
    "        embed2 = self.embedding(data_s2)\n",
    "        \n",
    "#         print(embed1.size())\n",
    "        rnn_out1_, hidden1 = self.rnn(embed1, self.hidden1)\n",
    "        rnn_out2_, hidden2 = self.rnn(embed2, self.hidden2)\n",
    "#         print(self.hidden1.size())\n",
    "\n",
    "        rnn_out1 = torch.sum(hidden1, dim=0)\n",
    "        rnn_out2 = torch.sum(hidden2, dim=0)\n",
    "#         print(rnn_out1.size())\n",
    "        combined_out = torch.cat([rnn_out1, rnn_out2], dim=1)\n",
    "#         print(combined_out.size())\n",
    "        logits = F.relu(self.linear1(combined_out))\n",
    "        res = self.linear2(logits)\n",
    "        \n",
    "        return res\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RNN(\n",
       "  (embedding): Embedding(100002, 300, padding_idx=0)\n",
       "  (rnn): GRU(300, 500, num_layers=2, batch_first=True)\n",
       "  (linear1): Linear(in_features=1000, out_features=500, bias=True)\n",
       "  (linear2): Linear(in_features=500, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model =torch.load(\"model_rnn4\")\n",
    "model.train(False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fiction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46.130653266331656\n",
      "----------\n",
      "telephone\n",
      "44.776119402985074\n",
      "----------\n",
      "slate\n",
      "41.01796407185629\n",
      "----------\n",
      "government\n",
      "40.6496062992126\n",
      "----------\n",
      "travel\n",
      "42.66802443991853\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for gen in ['fiction', 'telephone', 'slate', 'government', 'travel']:\n",
    "    data_d = df_test[df_test['genre']==gen]\n",
    "    print(gen)\n",
    "    test_genre(data_d,model)\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:30: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n",
      "/home/cvh255/pyenv/py3.6.3/lib/python3.6/site-packages/ipykernel_launcher.py:31: UserWarning: RNN module weights are not part of single contiguous chunk of memory. This means they need to be compacted at every call, possibly greatly increasing memory usage. To compact weights again call flatten_parameters().\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total accuracy 43.22\n"
     ]
    }
   ],
   "source": [
    "fns,pred_false,tns,pred_true,actual_out,actual_true_out = print_wront(df_test,model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Incorrect Predictions by RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 0\n",
      "Actual 1\n",
      "sentence1:  her voice was doubtful .\n",
      "sentence2 :  she sounded doubtful about it .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 0\n",
      "Actual 1\n",
      "sentence1:  they do n't call them immigrants anymore that was back during my granddaddy 's day\n",
      "sentence2 :  they used to call them immigrants .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 0\n",
      "sentence1:  this provides insight into the important japanese concept of katachi ( form ) , the rough equivalent of it is n't what you do ; it 's the way that you do it .\n",
      "sentence2 :  all japanese people abide by the concept of katachi .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 2\n",
      "Actual 1\n",
      "sentence1:  most of france went enthusiastically into world war i , and came out of it victorious yet bled white .\n",
      "sentence2 :  most of france supported wwi .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 2\n",
      "Actual 1\n",
      "sentence1:  shall i tell you what it would be like for your soul to live in the muck of a swamp in a mandrake root ? dave shook his head .\n",
      "sentence2 :  shall i tell you how your soul could live in a mandrake root ?\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 2\n",
      "sentence1:  and uh really they 're about it they 've got a guy named herb williams that that i guess sort of was supposed to take the place of uh tarpley but he uh he just does n't have the offensive skills\n",
      "sentence2 :  herb williams and tarpley are on par in terms of skills .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(fns)):\n",
    "    print(\"predicted\",pred_false[i][0])\n",
    "    print(\"Actual\",actual_out[i])\n",
    "    print(\"sentence1: \",' '.join(df_test.iloc[fns[i]][\"sentence1\"]))    \n",
    "    print(\"sentence2 : \",' '.join(df_test.iloc[fns[i]][\"sentence2\"]))\n",
    "    print()\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correct predictions by RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted 0\n",
      "Actual 0\n",
      "sentence1 :  pro-choicers point out that these close-up images literally cut the fetus 's context -- the woman -- out of the picture .\n",
      "sentence2 :  pro-choices say the close-up images are unfair to women .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 2\n",
      "Actual 2\n",
      "sentence1 :  however , assuming the procedural requirements of chapter 36 are met , changes negotiated by the postal service and a mail user for their mutual benefit may merit recommendation under the applicable statutory standards .\n",
      "sentence2 :  changes negotiated by the postal service are too regular and prohibit my postal services .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 1\n",
      "Actual 1\n",
      "sentence1 :  no . i guess i 'm going too .\n",
      "sentence2 :  i 'll come along .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 0\n",
      "Actual 0\n",
      "sentence1 :  the governing statute provides that a committee consisting of the comptroller general , the speaker of the house and president pro tempore of the senate , the majority and minority leaders , and the chairmen and ranking minority members of the senate governmental affairs and house government reform committees recommend an individual to the president for appointment .\n",
      "sentence2 :  the process is long and will be reformed in the coming years .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n",
      "predicted 2\n",
      "Actual 2\n",
      "sentence1 :  made by the fcic based on such comments are discussed in the preambles to the final rules .\n",
      "sentence2 :  there is no preamble to the end rules .\n",
      "\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(tns)):\n",
    "    print(\"predicted\",pred_true[i][0])\n",
    "    print(\"Actual\",actual_true_out[i])\n",
    "    print(\"sentence1 : \",' '.join(df_test.iloc[tns[i]][\"sentence1\"]))\n",
    "    print(\"sentence2 : \",' '.join(df_test.iloc[tns[i]][\"sentence2\"]))\n",
    "    print()\n",
    "    print(\"-\"*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
